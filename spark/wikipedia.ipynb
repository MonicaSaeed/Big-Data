{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"PopularWikipediaPages\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    try:\n",
    "        fields = line.split()\n",
    "        project = fields[0]\n",
    "        title = fields[1]\n",
    "        hits = int(fields[2])\n",
    "        size = int(fields[3])\n",
    "        return (project, title, hits, size)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing line:\", line)\n",
    "        print(\"Exception:\", e)\n",
    "        return None\n",
    "\n",
    "# Read the data from the file using parseLine function\n",
    "lines = sc.textFile(\"pagecounts-20160101-000000_parsed.out\")\n",
    "rdd = lines.map(parseLine).filter(lambda x: x is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min page size: 0, Max page size: 141180155987, Average page size: 132215.79814237214\n"
     ]
    }
   ],
   "source": [
    "# Compute min, max, and average page sizes\n",
    "minSize = rdd.map(lambda x: x[3]).min()\n",
    "maxSize = rdd.map(lambda x: x[3]).max()\n",
    "avgSize = rdd.map(lambda x: x[3]).mean()\n",
    "\n",
    "print(\"Min page size: {}, Max page size: {}, Average page size: {}\".format(minSize, maxSize, avgSize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English The titles count: 10292\n"
     ]
    }
   ],
   "source": [
    "# # Count page titles that start with \"The\"\n",
    "# the_titles_count = rdd.filter(lambda x: x[1].startswith(\"The\")).count()\n",
    "\n",
    "# Count page titles that start with \"The\" and are not part of the English project\n",
    "english_the_titles_count = rdd.filter(lambda x: x[0] != \"en\" and x[1].startswith(\"The\")).count()\n",
    "# print(\"The titles count: {}, English The titles count: {}\".format(the_titles_count, english_the_titles_count))\n",
    "\n",
    "print(\"English The titles count: {}\".format(english_the_titles_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['271_ac', 'categoryuser_th', 'chiron_elias_krase', 'dassault_rafaele', 'edesv']\n",
      "['271', 'ac', 'categoryuser', 'th', 'chiron']\n",
      "Number of unique terms appearing in the page titles: 1688528\n"
     ]
    }
   ],
   "source": [
    "def preprocess_title(title):\n",
    "    # Lowercase the title\n",
    "    title = title.lower()\n",
    "    # Remove non-alphanumeric characters an\n",
    "    title = re.sub(r'[^a-z0-9_]', '', title)\n",
    "    return title\n",
    "\n",
    "# Preprocess page titles\n",
    "preprocessed_titles = rdd.map(lambda x: preprocess_title(x[1]))\n",
    "print(preprocessed_titles.take(5))\n",
    "\n",
    "# Split titles into terms and flatten\n",
    "terms = preprocessed_titles.flatMap(lambda title: title.split(\"_\"))\n",
    "print(terms.take(5))\n",
    "\n",
    "# Count unique terms\n",
    "unique_terms_count = terms.distinct().count()\n",
    "\n",
    "print(\"Number of unique terms appearing in the page titles:\", unique_terms_count)\n",
    "\n",
    "\n",
    "# re.sub(): This function is used for performing substitutions based on regular expressions. It takes three main arguments:\n",
    "# The first argument is the regular expression pattern to search for.\n",
    "# The second argument is the replacement string, which will replace the matched pattern.\n",
    "# The third argument is the string on which the operation is performed.\n",
    "# r'[^a-zA-Z0-9_]': This regular expression pattern matches any character that is not alphanumeric (a-z, A-Z, 0-9) or an underscore _.\n",
    "# '': This is the replacement string, which is an empty string. It means that any character that matches the pattern will be removed (replaced with nothing).\n",
    "# 'title: This is the string on which the substitution operation is performed. In this case, it's the page title.\n",
    "# So, the re.sub() function will remove all characters from the page title that are not alphanumeric or underscores.\n",
    "\n",
    "# [\"hello world\", \"foo bar\", \"baz\"]\n",
    "# map\n",
    "# [\"hello\", \"world\"]\n",
    "# [\"foo\", \"bar\"]\n",
    "# [\"baz\"]\n",
    "# flatMap\n",
    "# [\"hello\", \"world\", \"foo\", \"bar\", \"baz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: E.Desv, Count: 6\n",
      "Title: Special:Contributions/5.232.61.79, Count: 1\n",
      "Title: Special:ListFiles/Nyttend, Count: 1\n",
      "Title: Special:WhatLinksHere/Main_Page, Count: 8\n",
      "Title: Time_Inc, Count: 4\n",
      "Title: Special:Contributions/MBisanz, Count: 1\n",
      "Title: Special:UserLogin, Count: 13\n",
      "Title: Acanthophorus_serraticornis, Count: 6\n",
      "Title: Allen_R._Schindler,_Jr, Count: 6\n",
      "Title: Annales._Histoire,_Sciences_Sociales/en/Annales_d, Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Extract each title and the number of times it was repeated\n",
    "title_counts = rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "for title, count in title_counts.take(10):\n",
    "    print(\"Title: {}, Count: {}\".format(title, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined titles:\n",
      "Title: E.Desv, Data: [('aa', 1, 4662), ('arc', 1, 5210), ('ast', 1, 4825), ('fiu-vro', 1, 5237), ('fr', 1, 7057), ('ik', 1, 4548)]\n",
      "Title: Special:WhatLinksHere/Main_Page, Data: [('aa', 1, 5556), ('commons.m', 2, 15231), ('en', 5, 101406), ('en.s', 1, 8597), ('en.voy', 1, 8550), ('meta.m', 1, 11529), ('outreach.m', 1, 5698), ('simple', 3, 32145)]\n",
      "Title: Time_Inc, Data: [('aa', 1, 4672), ('af', 1, 6182), ('ha', 1, 4842), ('na', 1, 4923)]\n",
      "Title: Special:UserLogin, Data: [('aa.d', 1, 4899), ('commons.m', 30, 181938), ('en', 44198, 718770014), ('en.q', 4, 34449), ('incubator.m', 1, 5221), ('m.f', 13, 58547), ('m.w', 3, 12523), ('m.wd', 2, 8696), ('meta.m', 1, 5311), ('simple', 2, 9960), ('ss', 1, 5052), ('www.w', 5, 49952), ('www.wd', 1, 4989)]\n",
      "Title: Acanthophorus_serraticornis, Data: [('ab', 1, 5942), ('ckb', 1, 5825), ('csb', 1, 5480), ('de', 1, 5510), ('dsb', 1, 5429), ('fj', 1, 4693)]\n",
      "Title: Allen_R._Schindler,_Jr, Data: [('ab', 1, 5957), ('ckb', 1, 5840), ('fj', 1, 4711), ('kab', 1, 4900), ('lij', 1, 4881), ('uk', 1, 7322)]\n",
      "Title: Annales._Histoire,_Sciences_Sociales/en/Annales_d, Data: [('ab', 1, 6008), ('es', 1, 7775), ('fi', 1, 5678), ('sr', 1, 6100)]\n",
      "Title: N.P.R, Data: [('ab', 1, 5900), ('csb', 1, 5438), ('hsb', 1, 5000), ('kab', 1, 4853), ('kj', 1, 4659), ('pl', 1, 6338), ('pt', 1, 7159)]\n",
      "Title: Nord-Pas-de-Calais, Data: [('ab', 1, 5925), ('ckb', 1, 5806), ('csb', 1, 5460), ('de', 4, 120526), ('en', 2, 168302), ('eu', 1, 14875), ('fr', 8, 450792), ('pl', 1, 17938), ('ro', 1, 18515), ('ur', 1, 7716)]\n",
      "Title: Agnes_Monica, Data: [('ace', 1, 13278), ('en', 1, 44900), ('sh', 1, 16203), ('tw', 1, 12184), ('zh', 1, 72848)]\n"
     ]
    }
   ],
   "source": [
    "# Combine between data of pages with the same title and save each pair of pages data in order to display them\n",
    "combined_titles = rdd.map(lambda x: (x[1], (x[0], x[2], x[3]))).groupByKey().filter(lambda x: len(x[1]) > 1).mapValues(list)\n",
    "# combined_titles = rdd.map(lambda x: (x[1], (x[0], x[2], x[3]))).groupByKey().filter(lambda x: len(x[1]) > 1).mapValues(list)\n",
    "\n",
    "print(\"Combined titles:\")\n",
    "for title, data in combined_titles.take(10):\n",
    "    print(\"Title: {}, Data: {}\".format(title, data))\n",
    "\n",
    "# mapValues(list) to convert the iterator of values into a list. This will give you each title paired with a list of its corresponding data tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a document includes all the results of each query\n",
    "with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Min page size: {}\\n\".format(minSize))\n",
    "    f.write(\"Max page size: {}\\n\".format(maxSize))\n",
    "    f.write(\"Average page size: {}\\n\".format(avgSize))\n",
    "    f.write(\"English The titles count: {}\\n\".format(english_the_titles_count))\n",
    "    f.write(\"Number of unique terms appearing in the page titles: {}\\n\".format(unique_terms_count))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Title Counts:\\n\")\n",
    "    for title, count in title_counts.collect():\n",
    "        f.write(\"{}: {}\\n\".format(title, count))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Combined Titles:\\n\")\n",
    "    for title, data_list in combined_titles.collect():\n",
    "        f.write(\"{}:\\n\".format(title))\n",
    "        for data in data_list:\n",
    "            f.write(\"{}\\n\".format(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the existing SparkContext\n",
    "sc.stop()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
